#!/usr/bin/env python3
"""
Agent Router - æ™ºèƒ½æµè§ˆå™¨è‡ªåŠ¨åŒ– API ç«¯ç‚¹
åŸºäº apibrowser é¡¹ç›®é›†æˆåˆ° backend
"""

import asyncio
import os
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime

# å¯¼å…¥æ™ºèƒ½åŠŸèƒ½
try:
    from browser_use import Agent, BrowserProfile
    from browser_use.browser.profile import ProxySettings
    INTELLIGENT_AVAILABLE = True
except ImportError:
    INTELLIGENT_AVAILABLE = False

router = APIRouter()

# ==================== æ•°æ®æ¨¡å‹ ====================

class CompleteIntelligentBrowserTask(BaseModel):
    """å®Œæ•´çš„æ™ºèƒ½æµè§ˆå™¨ä»»åŠ¡è¯·æ±‚ - åŒ…å«æ‰€æœ‰åŸé¡¹ç›®å‚æ•°"""
    # åŸºç¡€ä»»åŠ¡å‚æ•°
    task: str = Field(..., description="è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°")
    url: Optional[str] = Field("https://google.com", description="èµ·å§‹ URL")
    
    # æ‰§è¡Œæ§åˆ¶å‚æ•°
    max_steps: Optional[int] = Field(8, description="æœ€å¤§æ‰§è¡Œæ­¥éª¤æ•°")
    use_vision: Optional[bool] = Field(True, description="æ˜¯å¦ä½¿ç”¨è§†è§‰è¯†åˆ«")
    max_actions_per_step: Optional[int] = Field(2, description="æ¯æ­¥æœ€å¤§åŠ¨ä½œæ•°")
    
    # LLM æ¨¡å‹å‚æ•°
    model_provider: Optional[str] = Field(None, description="æ¨¡å‹æä¾›å•† (openai/anthropic/deepseek/ollama/azure)")
    model_name: Optional[str] = Field(None, description="å…·ä½“æ¨¡å‹åç§°")
    temperature: Optional[float] = Field(0.3, description="æ¨¡å‹æ¸©åº¦å‚æ•°")
    
    # æµè§ˆå™¨é…ç½®å‚æ•°
    headless: Optional[bool] = Field(False, description="æ˜¯å¦æ— å¤´æ¨¡å¼")
    viewport_width: Optional[int] = Field(1920, description="è§†å£å®½åº¦")
    viewport_height: Optional[int] = Field(1080, description="è§†å£é«˜åº¦")
    chrome_path: Optional[str] = Field(None, description="Chrome å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„")
    disable_security: Optional[bool] = Field(False, description="æ˜¯å¦ç¦ç”¨å®‰å…¨ç‰¹æ€§")
    device_scale_factor: Optional[float] = Field(None, description="è®¾å¤‡åƒç´ æ¯”(DPI)ï¼Œä¾‹å¦‚2.0ã€3.0")
    no_viewport: Optional[bool] = Field(False, description="æ˜¯å¦ç¦ç”¨è§†å£è®¾ç½®ï¼Œä¸ headless=True ä¸å¯åŒæ—¶ä¸ºçœŸ")
    window_position_x: Optional[int] = Field(0, description="çª—å£Xä½ç½®(ä»…æœ‰å¤´æ¨¡å¼)")
    window_position_y: Optional[int] = Field(0, description="çª—å£Yä½ç½®(ä»…æœ‰å¤´æ¨¡å¼)")
    channel: Optional[str] = Field(None, description="æµè§ˆå™¨æ¸ é“ï¼Œå¦‚ chromiumã€chromeã€msedge")
    devtools: Optional[bool] = Field(False, description="å¯åŠ¨æ—¶æ‰“å¼€å¼€å‘è€…å·¥å…·ï¼Œä»…åœ¨ headless=False æ—¶ç”Ÿæ•ˆ")
    slow_mo: Optional[float] = Field(0, description="æ”¾æ…¢åŠ¨ä½œé€Ÿåº¦(æ¯«ç§’)")
    chromium_sandbox: Optional[bool] = Field(None, description="æ˜¯å¦å¯ç”¨Chromium Sandbox")
    keep_alive: Optional[bool] = Field(None, description="ä»»åŠ¡ç»“æŸåæ˜¯å¦ä¿æŒæµè§ˆå™¨å­˜æ´»")
    enable_default_extensions: Optional[bool] = Field(True, description="å¯ç”¨è‡ªåŠ¨åŒ–æ‰©å±•(å¹¿å‘Šæ‹¦æˆª/æ¸…ç†Cookie/URLæ¸…ç†)")
    deterministic_rendering: Optional[bool] = Field(False, description="å¯ç”¨ç¡®å®šæ€§æ¸²æŸ“(ä¸æ¨è)")
    cross_origin_iframes: Optional[bool] = Field(False, description="å¯ç”¨è·¨åŸŸiframeæ”¯æŒ")
    highlight_elements: Optional[bool] = Field(True, description="é«˜äº®å¯äº¤äº’å…ƒç´ ä»¥ä¾¿è§†è§‰è¯†åˆ«")
    
    # ç½‘ç»œå’Œä»£ç†å‚æ•°
    proxy_server: Optional[str] = Field(None, description="ä»£ç†æœåŠ¡å™¨åœ°å€")
    proxy_bypass: Optional[str] = Field(None, description="ä»£ç†ç»•è¿‡åˆ—è¡¨ï¼Œé€—å·åˆ†éš”")
    proxy_username: Optional[str] = Field(None, description="ä»£ç†ç”¨æˆ·å")
    proxy_password: Optional[str] = Field(None, description="ä»£ç†å¯†ç ")
    user_agent: Optional[str] = Field(None, description="è‡ªå®šä¹‰ User-Agent")
    ignore_https_errors: Optional[bool] = Field(False, description="æ˜¯å¦å¿½ç•¥ HTTPS é”™è¯¯")
    extra_http_headers: Optional[Dict[str, str]] = Field(None, description="é¢å¤– HTTP å¤´(ä»…è¿œç¨‹æµè§ˆå™¨)")
    
    # å½•åˆ¶å’Œè¿½è¸ªå‚æ•°
    save_recording: Optional[bool] = Field(False, description="æ˜¯å¦ä¿å­˜å½•åˆ¶è§†é¢‘")
    recording_path: Optional[str] = Field(None, description="å½•åˆ¶æ–‡ä»¶ä¿å­˜è·¯å¾„")
    enable_trace: Optional[bool] = Field(False, description="æ˜¯å¦å¯ç”¨æ‰§è¡Œè¿½è¸ª")
    trace_path: Optional[str] = Field(None, description="è¿½è¸ªæ–‡ä»¶ä¿å­˜è·¯å¾„")
    save_screenshots: Optional[bool] = Field(False, description="æ˜¯å¦ä¿å­˜æ­¥éª¤æˆªå›¾")
    record_har_path: Optional[str] = Field(None, description="ä¿å­˜ç½‘ç»œHARæ–‡ä»¶åˆ°è¯¥è·¯å¾„")
    record_har_mode: Optional[str] = Field(None, description="HARæ¨¡å¼: full|minimal")
    record_har_content: Optional[str] = Field(None, description="HARå†…å®¹: embed|omit|attach")
    
    # é«˜çº§é…ç½®å‚æ•°
    cookies_file: Optional[str] = Field(None, description="Cookie æ–‡ä»¶è·¯å¾„")
    extra_chromium_args: Optional[List[str]] = Field(None, description="é¢å¤–çš„ Chromium å¯åŠ¨å‚æ•°")
    wss_url: Optional[str] = Field(None, description="WebSocket è°ƒè¯• URL")
    downloads_path: Optional[str] = Field(None, description="ä¸‹è½½ç›®å½•")
    accept_downloads: Optional[bool] = Field(True, description="æ˜¯å¦è‡ªåŠ¨æ¥å—ä¸‹è½½")
    allowed_domains: Optional[List[str]] = Field(None, description="å…è®¸è®¿é—®çš„åŸŸååˆ—è¡¨")
    service_workers: Optional[str] = Field(None, description="Service Workers ç­–ç•¥: allow|block")
    locale: Optional[str] = Field(None, description="é¡µé¢ locale")
    timezone_id: Optional[str] = Field(None, description="æ—¶åŒºIDï¼Œå¦‚ Asia/Shanghai")

class DetailedStepInfo(BaseModel):
    """è¯¦ç»†çš„æ‰§è¡Œæ­¥éª¤ä¿¡æ¯"""
    step_number: int
    action: str
    reasoning: Optional[str] = None
    success: bool
    error: Optional[str] = None
    execution_time: Optional[float] = None

class CompleteTaskResult(BaseModel):
    """å®Œæ•´çš„ä»»åŠ¡ç»“æœ"""
    success: bool
    result: Optional[str] = None
    error: Optional[str] = None
    mode: str
    steps: Optional[List[DetailedStepInfo]] = None
    total_steps: Optional[int] = None
    execution_time: Optional[float] = None
    model_used: Optional[str] = None
    config_used: Optional[Dict[str, Any]] = None
    recording_file: Optional[str] = None
    trace_file: Optional[str] = None
    screenshots: Optional[List[str]] = None
    final_url: Optional[str] = None
    final_title: Optional[str] = None
    cookies_saved: Optional[str] = None

# ==================== LLM åˆ›å»ºå‡½æ•° ====================

def create_llm(provider: str = None, model_name: str = None, temperature: float = 0.3):
    """åˆ›å»º LLM å®ä¾‹ - æ”¯æŒå®Œæ•´çš„æ¨¡å‹æä¾›å•†"""
    print(f"ğŸ”§ å°è¯•åˆ›å»º LLM - Provider: {provider}, Model: {model_name}")
    
    # å¯¼å…¥æˆ‘ä»¬çš„ LLM å·¥å‚
    from .core.utils.utils import get_llm_model, model_names
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•
    if not provider:
        if os.getenv("DEEPSEEK_API_KEY"):
            provider = "deepseek"
        elif os.getenv("OPENAI_API_KEY"):
            provider = "openai"
        elif os.getenv("ANTHROPIC_API_KEY"):
            provider = "anthropic"
        else:
            return None, "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ API key"
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
    if not model_name:
        available_models = model_names.get(provider.lower(), [])
        if available_models:
            model_name = available_models[0]
        else:
            return None, f"æä¾›å•† {provider} æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹"
    
    try:
        # ä½¿ç”¨æˆ‘ä»¬çš„ get_llm_model å‡½æ•°
        llm = get_llm_model(
            provider=provider,
            model_name=model_name,
            temperature=temperature
        )
        
        # æµ‹è¯•è¿æ¥
        print("ğŸ” æµ‹è¯• LLM è¿æ¥...")
        test_response = llm.invoke("Hello")
        print(f"âœ… LLM è¿æ¥æˆåŠŸ: {test_response.content[:50]}...")
        return llm, f"{provider.title()} {model_name}"
            
    except Exception as e:
        error_msg = f"LLM åˆ›å»ºå¤±è´¥ ({provider}): {str(e)}"
        print(f"âŒ {error_msg}")
        return None, error_msg

# ==================== æ ¸å¿ƒæ‰§è¡Œå‡½æ•° ====================

async def execute_complete_task(request: CompleteIntelligentBrowserTask) -> CompleteTaskResult:
    """æ‰§è¡Œå®Œæ•´çš„æ™ºèƒ½æµè§ˆå™¨ä»»åŠ¡ - åŸºäºå·¥ä½œç‰ˆæœ¬"""
    task_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    start_time = asyncio.get_event_loop().time()
    
    print(f"ğŸš€ å¼€å§‹å®Œæ•´æ™ºèƒ½ä»»åŠ¡ - ID: {task_id}")
    print(f"ğŸ“‹ ä»»åŠ¡æè¿°: {request.task}")
    print(f"ğŸŒ èµ·å§‹ URL: {request.url}")
    
    if not INTELLIGENT_AVAILABLE:
        return CompleteTaskResult(
            success=False,
            error="æ™ºèƒ½åŠŸèƒ½ä¸å¯ç”¨ï¼šç¼ºå°‘ browser-use ä¾èµ–",
            mode="intelligent",
            execution_time=asyncio.get_event_loop().time() - start_time
        )
    
    # åˆ›å»º LLM
    llm, model_info = create_llm(request.model_provider, request.model_name, request.temperature)
    if not llm:
        execution_time = asyncio.get_event_loop().time() - start_time
        return CompleteTaskResult(
            success=False,
            error=f"LLM åˆ›å»ºå¤±è´¥: {model_info}",
            mode="intelligent",
            execution_time=execution_time
        )
    
    try:
        print(f"ğŸ§  æ™ºèƒ½æ¨¡å¼ - ä½¿ç”¨ {model_info}")
        print(f"ğŸ¯ ä»»åŠ¡: {request.task}")
        
        # å¤„ç†è§†è§‰è¯†åˆ«è®¾ç½®
        use_vision = request.use_vision
        if request.model_provider == "deepseek":
            print("âš ï¸ DeepSeek ä¸æ”¯æŒè§†è§‰è¯†åˆ«ï¼Œè‡ªåŠ¨è®¾ç½® use_vision=False")
            use_vision = False
        
        print(f"ğŸ‘ï¸ è§†è§‰è¯†åˆ«: {use_vision}")
        print(f"ğŸ”§ é…ç½®æµè§ˆå™¨å‚æ•°: headless={request.headless}, viewport={request.viewport_width}x{request.viewport_height}")
        
        # ä½¿ç”¨ BrowserProfileï¼ˆå®˜æ–¹å…¼å®¹å±‚ï¼‰ä»¥é¿å… Pydantic æ ¡éªŒé”™è¯¯
        profile = BrowserProfile(
            headless=request.headless,
            window_size={'width': request.viewport_width or 1920, 'height': request.viewport_height or 1080},
            viewport={'width': request.viewport_width or 1920, 'height': request.viewport_height or 1080},
            no_viewport=bool(request.no_viewport),
            user_agent=request.user_agent,
            disable_security=bool(request.disable_security),
            device_scale_factor=request.device_scale_factor,
            window_position={'width': request.window_position_x or 0, 'height': request.window_position_y or 0} if request.window_position_x is not None and request.window_position_y is not None else None,
            channel=request.channel,
            devtools=bool(request.devtools),
            slow_mo=request.slow_mo or 0,
            chromium_sandbox=request.chromium_sandbox if request.chromium_sandbox is not None else (True),
            keep_alive=request.keep_alive,
            enable_default_extensions=True if request.enable_default_extensions is None else request.enable_default_extensions,
            deterministic_rendering=bool(request.deterministic_rendering),
            cross_origin_iframes=bool(request.cross_origin_iframes),
            highlight_elements=True if request.highlight_elements is None else request.highlight_elements,
            ignore_https_errors=bool(request.ignore_https_errors),
            extra_http_headers=request.extra_http_headers or {},
            traces_dir=request.trace_path,
            record_har_path=request.record_har_path,
            record_har_mode=request.record_har_mode,  # type: ignore
            record_har_content=request.record_har_content,  # type: ignore
            record_video_dir=request.recording_path if request.save_recording else None,
            downloads_path=request.downloads_path,
            accept_downloads=True if request.accept_downloads is None else request.accept_downloads,
            allowed_domains=request.allowed_domains or None,
            locale=request.locale,
            timezone_id=request.timezone_id,
        )
        if request.extra_chromium_args:
            profile.args = request.extra_chromium_args
        if request.wss_url:
            profile.cdp_url = None
            profile.wss_url = request.wss_url
        if request.chrome_path:
            profile.executable_path = request.chrome_path
        if request.proxy_server or request.proxy_bypass or request.proxy_username or request.proxy_password:
            profile.proxy = ProxySettings(
                server=request.proxy_server,
                bypass=request.proxy_bypass,
                username=request.proxy_username,
                password=request.proxy_password,
            )

        print(f"ğŸ“ BrowserProfile: headless={profile.headless}, window={profile.window_size}, viewport={profile.viewport}")

        # ç›´æ¥å°† profile ä¼ å…¥ Agentï¼ˆbrowser-use ä¼šåˆ›å»º BrowserSessionï¼‰
        browser = None
        browser_context = None
        
        try:
            # åˆ›å»ºæ™ºèƒ½ä»£ç† - ä½¿ç”¨å®˜æ–¹æ–¹å¼
            agent = Agent(
                task=request.task,
                llm=llm,
                browser=None,
                browser_context=None,
                browser_profile=profile,
                use_vision=use_vision,
                max_actions_per_step=request.max_actions_per_step or 2,
                generate_gif=False
            )

            print("ğŸš€ å¼€å§‹æ™ºèƒ½æ‰§è¡Œ...")
            history = await agent.run(max_steps=request.max_steps)
            
            # è§£ææ‰§è¡Œæ­¥éª¤ - ä½¿ç”¨ä¸ fixed_enhanced_api.py ç›¸åŒçš„æ–¹å¼
            steps = []
            for i, step in enumerate(history.history):
                step_info = DetailedStepInfo(
                    step_number=i + 1,
                    action=str(getattr(step, 'action', f'Step {i+1}')),
                    reasoning=getattr(step, 'reasoning', None),
                    success=not bool(getattr(step, 'error', None)),
                    error=str(getattr(step, 'error', None)) if getattr(step, 'error', None) else None,
                    execution_time=getattr(step, 'execution_time', None)
                )
                steps.append(step_info)
                
                status = "âœ…" if step_info.success else "âŒ"
                print(f"  {status} æ­¥éª¤ {i+1}: {step_info.action}")
            
            final_result = history.final_result() or "æ™ºèƒ½ä»»åŠ¡æ‰§è¡Œå®Œæˆ"
            execution_time = asyncio.get_event_loop().time() - start_time
            
            print(f"ğŸ¯ æœ€ç»ˆç»“æœ: {final_result}")
            
            # åˆ›å»ºé…ç½®ä¿¡æ¯
            config_used = {
                "task_id": task_id,
                "viewport": f"{request.viewport_width or 1920}x{request.viewport_height or 1080}",
                "headless": request.headless,
                "use_vision": use_vision,
                "max_steps": request.max_steps,
                "max_actions_per_step": request.max_actions_per_step,
                "model": model_info,
                "temperature": request.temperature,
                "chrome_path": request.chrome_path,
                "proxy": request.proxy_server,
                "user_agent": request.user_agent,
                "recording": request.save_recording,
                "trace": request.enable_trace,
                "screenshots": request.save_screenshots,
                "disable_security": request.disable_security,
                "ignore_https_errors": request.ignore_https_errors,
                "no_viewport": request.no_viewport
            }
            
            return CompleteTaskResult(
                success=True,
                result=final_result,
                mode="intelligent",
                steps=steps,
                total_steps=len(steps),
                execution_time=execution_time,
                model_used=model_info,
                config_used=config_used,
                trace_file=f"{request.trace_path or './traces'}/trace_{task_id}.zip" if request.enable_trace else None
            )
            
        finally:
            # æ¸…ç†èµ„æº
            try:
                if browser_context:
                    await browser_context.close()
                if browser:
                    await browser.close()
            except Exception as cleanup_error:
                print(f"âš ï¸ æ¸…ç†èµ„æºæ—¶å‡ºé”™: {cleanup_error}")
        
    except Exception as e:
        execution_time = asyncio.get_event_loop().time() - start_time
        error_msg = f"æ™ºèƒ½æ‰§è¡Œå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        import traceback
        traceback.print_exc()  # æ·»åŠ è¯¦ç»†é”™è¯¯ä¿¡æ¯
        
        return CompleteTaskResult(
            success=False,
            error=error_msg,
            mode="intelligent",
            model_used=model_info if 'model_info' in locals() else "Unknown",
            execution_time=execution_time
        )

# ==================== API ç«¯ç‚¹ ====================

@router.post("/complete-browser-task", response_model=CompleteTaskResult)
async def complete_browser_task(request: CompleteIntelligentBrowserTask):
    """
    æ‰§è¡Œå®Œæ•´çš„æ™ºèƒ½æµè§ˆå™¨ä»»åŠ¡
    
    åŸºäºå·²éªŒè¯å·¥ä½œçš„ apibrowser é¡¹ç›®ï¼Œæ”¯æŒå®Œæ•´å‚æ•°é…ç½®
    """
    print("ğŸŒ HTTP è¯·æ±‚å¼€å§‹")
    print(f"  â€¢ ä»»åŠ¡: {request.task}")
    print(f"  â€¢ æ¨¡å‹: {request.model_provider} {request.model_name}")
    print(f"  â€¢ æœ€å¤§æ­¥æ•°: {request.max_steps}")
    print(f"  â€¢ è§†è§‰è¯†åˆ«: {request.use_vision}")
    print(f"  â€¢ è¯·æ±‚å¯¹è±¡ç±»å‹: {type(request)}")
    
    result = await execute_complete_task(request)
    
    print("ğŸŒ HTTP è¯·æ±‚å®Œæˆ")
    print(f"  â€¢ æˆåŠŸçŠ¶æ€: {result.success}")
    print(f"  â€¢ æ€»æ­¥æ•°: {result.total_steps}")
    print(f"  â€¢ æ­¥éª¤æ•°é‡: {len(result.steps) if result.steps else 0}")
    if result.steps and len(result.steps) > 0:
        print(f"  â€¢ ç¬¬ä¸€ä¸ªæ­¥éª¤: {result.steps[0].action}")
    print(f"  â€¢ ç»“æœå¯¹è±¡ç±»å‹: {type(result)}")
    
    return result

@router.get("/status")
async def agent_status():
    """æ£€æŸ¥ Agent æœåŠ¡çŠ¶æ€"""
    # æ£€æŸ¥ API keys çŠ¶æ€
    deepseek_available = bool(os.getenv("DEEPSEEK_API_KEY"))
    openai_available = bool(os.getenv("OPENAI_API_KEY"))
    anthropic_available = bool(os.getenv("ANTHROPIC_API_KEY"))
    
    return {
        "service": "æ™ºèƒ½æµè§ˆå™¨è‡ªåŠ¨åŒ– Agent",
        "version": "1.0.0",
        "intelligent_features": {
            "available": INTELLIGENT_AVAILABLE,
            "deepseek_api_key": "å·²é…ç½®" if deepseek_available else "æœªé…ç½®",
            "openai_api_key": "å·²é…ç½®" if openai_available else "æœªé…ç½®",
            "anthropic_api_key": "å·²é…ç½®" if anthropic_available else "æœªé…ç½®"
        },
        "supported_models": {
            "deepseek": ["deepseek-chat", "deepseek-coder"],
            "openai": ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"],
            "anthropic": ["claude-3-5-sonnet-20241022", "claude-3-5-haiku-20241022"],
            "ollama": ["llama3.2", "qwen2.5", "gemma2"],
            "azure": ["gpt-4", "gpt-35-turbo"]
        },
        "endpoints": {
            "POST /agent/complete-browser-task": "å®Œæ•´å‚æ•°æ™ºèƒ½æµè§ˆå™¨ä»»åŠ¡",
            "GET /agent/status": "æœåŠ¡çŠ¶æ€æ£€æŸ¥",
            "GET /agent/test-llm": "LLM è¿æ¥æµ‹è¯•"
        },
        "total_parameters": 20
    }

@router.get("/test-llm")
async def test_llm_connection():
    """æµ‹è¯• LLM è¿æ¥"""
    results = {}
    
    # æµ‹è¯• DeepSeek
    if os.getenv("DEEPSEEK_API_KEY"):
        llm, info = create_llm("deepseek", "deepseek-chat")
        results["deepseek"] = {
            "available": llm is not None,
            "info": info
        }
    else:
        results["deepseek"] = {
            "available": False,
            "info": "API key æœªé…ç½®"
        }
    
    # æµ‹è¯• OpenAI
    if os.getenv("OPENAI_API_KEY"):
        llm, info = create_llm("openai", "gpt-4o-mini")
        results["openai"] = {
            "available": llm is not None,
            "info": info
        }
    else:
        results["openai"] = {
            "available": False,
            "info": "API key æœªé…ç½®"
        }
    
    # æµ‹è¯• Anthropic
    if os.getenv("ANTHROPIC_API_KEY"):
        llm, info = create_llm("anthropic", "claude-3-5-haiku-20241022")
        results["anthropic"] = {
            "available": llm is not None,
            "info": info
        }
    else:
        results["anthropic"] = {
            "available": False,
            "info": "API key æœªé…ç½®"
        }
    
    return results
